# -*- coding: utf-8 -*-
"""Time-Series-Analysis-&-Forecasting.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ql7N5lgXZliQxD1iOgflFEyx-YsJeGwX

# MSFT Stock Forecasting: ARIMA vs LSTM

# 1. Time Series Analysis

**Importing Libraries.**
"""

import yfinance as yf
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
from statsmodels.tsa.stattools import adfuller
from datetime import datetime

"""**Load MSFT data past 5 years.**"""

msft = yf.download('MSFT', start='2018-01-01', end=datetime.today().strftime('%Y-%m-%d'))

"""**Visualize Close price.**"""

plt.plot(msft['Close'], label='Close Price')
plt.title('MSFT Close Price Over Time')
plt.xlabel('Date')
plt.ylabel('Price (USD)')
plt.legend()
plt.show()

"""**Rolling Averages.**"""

msft['MA7'] = msft['Close'].rolling(window=7).mean()
msft['MA30'] = msft['Close'].rolling(window=30).mean()

plt.figure(figsize=(14,6))
plt.plot(msft['Close'], label='Close')
plt.plot(msft['MA7'], label='7-Day MA')
plt.plot(msft['MA30'], label='30-Day MA')
plt.title('Moving Averages')
plt.legend()
plt.show()

"""**Seasonal Decomposition.**"""

result = seasonal_decompose(msft['Close'], model='additive', period=365)
result.plot()
plt.show()

"""**ACF and PACF.**"""

plot_acf(msft['Close'].dropna(), lags=40)
plt.show()

plot_pacf(msft['Close'].dropna(), lags=40)
plt.show()

"""**Stationarity Test.**"""

adf_result = adfuller(msft['Close'].dropna())
print("ADF Statistic:", adf_result[0])
print("p-value:", adf_result[1])

"""If the above results are  p > 0.05, data is non-stationary. Apply differencing

**Applying  Differencing.**
"""

msft_diff = msft['Close'].diff().dropna()

"""**Runing the ADF test again.**"""

adf_result = adfuller(msft_diff)
print("ADF Statistic (after differencing):", adf_result[0])
print("p-value (after differencing):", adf_result[1])

"""**There is a strong evidence of stationarity.**

# 2. ARIMA Forecasting
"""

from statsmodels.tsa.arima.model import ARIMA
from sklearn.metrics import mean_absolute_error, mean_squared_error
import math

"""**Differencing to make stationary.**"""

msft_diff = msft['Close'].diff().dropna()

"""**Fit ARIMA (example: (5,1,2) based on ACF/PACF).**"""

model = ARIMA(msft['Close'], order=(5,1,2))
model_fit = model.fit()

"""**Now we will go far  Forecast next 30 days.**"""

forecast = model_fit.get_forecast(steps=30)
forecast_df = forecast.conf_int()
forecast_df['Forecast'] = forecast.predicted_mean

"""**Now Ploting.**"""

plt.figure(figsize=(14,6))
plt.plot(msft['Close'], label='Historical')
plt.plot(forecast_df['Forecast'], label='Forecast', color='red')
plt.fill_between(forecast_df.index,
                 forecast_df['lower MSFT'],
                 forecast_df['upper MSFT'],
                 color='pink', alpha=0.3)
plt.title('ARIMA Forecast (30 Days)')
plt.legend()
plt.show()

"""*** Evaluation on last 30 days.***"""

actual = msft['Close'].iloc[-30:]
predicted = model_fit.predict(start=len(msft)-30, end=len(msft)-1, typ='levels')
mae_arima = mean_absolute_error(actual, predicted)
rmse_arima = math.sqrt(mean_squared_error(actual, predicted))
print("ARIMA MAE:", mae_arima)
print("ARIMA RMSE:", rmse_arima)

"""# 3. LSTM Forecasting

**Libraries.**
"""

from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense

"""**Prepareing data.**"""

data = msft[['Close']].values
scaler = MinMaxScaler()
data_scaled = scaler.fit_transform(data)

"""**Sliding window.**"""

def create_dataset(data, time_step=60):
    X, y = [], []
    for i in range(len(data)-time_step-1):
        X.append(data[i:(i+time_step), 0])
        y.append(data[i + time_step, 0])
    return np.array(X), np.array(y)

X, y = create_dataset(data_scaled)
X = X.reshape(X.shape[0], X.shape[1], 1)

"""**Spliting data for train and test.**"""

split = int(len(X)*0.8)
X_train, X_test = X[:split], X[split:]
y_train, y_test = y[:split], y[split:]

"""**Using LSTM Model.**"""

model_lstm = Sequential()
model_lstm.add(LSTM(50, return_sequences=False, input_shape=(X_train.shape[1], 1)))
model_lstm.add(Dense(1))
model_lstm.compile(loss='mean_squared_error', optimizer='adam')
model_lstm.fit(X_train, y_train, epochs=10, batch_size=64, verbose=1)

"""**Time for Prediction.**"""

lstm_preds = model_lstm.predict(X_test)
lstm_preds_rescaled = scaler.inverse_transform(lstm_preds.reshape(-1,1))
y_test_rescaled = scaler.inverse_transform(y_test.reshape(-1,1))

"""**Evaluation.**"""

mae_lstm = mean_absolute_error(y_test_rescaled, lstm_preds_rescaled)
rmse_lstm = math.sqrt(mean_squared_error(y_test_rescaled, lstm_preds_rescaled))
print("LSTM MAE:", mae_lstm)
print("LSTM RMSE:", rmse_lstm)

"""**Ploting.**"""

plt.figure(figsize=(14,6))
plt.plot(y_test_rescaled, label='Actual')
plt.plot(lstm_preds_rescaled, label='Predicted', color='red')
plt.title('LSTM Predictions vs Actual')
plt.legend()
plt.show()

"""# 4. Final Comparison & Reflection."""

print("\n--- Model Comparison ---")
print(f"ARIMA MAE:  {mae_arima:.4f}, RMSE:  {rmse_arima:.4f}")
print(f"LSTM  MAE:  {mae_lstm:.4f}, RMSE:  {rmse_lstm:.4f}")